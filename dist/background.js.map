{
  "version": 3,
  "sources": ["../src/background.ts"],
  "sourcesContent": ["import type {\n  ClassifyPostMessage,\n  ClassifyResponse,\n  ClearCacheResponse,\n  IncrementBlockedResponse,\n  LlmDecision,\n  LocalSettings,\n  PopupStateResponse,\n  RuntimeMessage,\n  SetOpenAiApiKeyResponse,\n  SyncSettings,\n  UsageResponse,\n  UsageStats,\n} from \"./types\";\n\nconst SYNC_DEFAULTS: SyncSettings = {\n  enabled: true,\n  threshold: 8,\n  customKeywords: [],\n  filterSelfPromotion: false,\n  llmEnabled: false,\n  openaiModel: \"gpt-4o-mini\",\n  llmHideConfidence: 0.68,\n  maxLlmCallsPerMonth: 1000,\n};\nconst SYNC_DEFAULT_RECORD: Record<string, unknown> = { ...SYNC_DEFAULTS };\n\nconst LOCAL_DEFAULTS: LocalSettings = {\n  openaiApiKey: \"\",\n  llmUsage: null,\n  llmCache: {},\n  blockedCount: 0,\n};\nconst LOCAL_DEFAULT_RECORD: Record<string, unknown> = { ...LOCAL_DEFAULTS };\n\nconst CACHE_TTL_MS = 30 * 24 * 60 * 60 * 1000;\nconst MAX_CACHE_ENTRIES = 600;\nconst CLASSIFIER_PROMPT_VERSION = \"2026-02-22-v4\";\n\nfunction monthKey(): string {\n  const now = new Date();\n  const month = String(now.getMonth() + 1).padStart(2, \"0\");\n  return `${now.getFullYear()}-${month}`;\n}\n\nfunction cleanReason(text: unknown): string {\n  return String(text || \"\")\n    .replace(/\\s+/g, \" \")\n    .trim()\n    .slice(0, 160);\n}\n\nfunction sanitizeConfidence(value: unknown, fallback = 0.5): number {\n  const n = Number(value);\n  if (!Number.isFinite(n)) return fallback;\n  return Math.max(0, Math.min(1, n));\n}\n\ninterface ParsedClassifierResult {\n  hide: boolean;\n  confidence: number;\n  category: string;\n  reason: string;\n}\n\nfunction parseClassifierResult(\n  content: string,\n  hideThreshold: number,\n): ParsedClassifierResult {\n  let parsed: Record<string, unknown>;\n  try {\n    parsed = JSON.parse(content) as Record<string, unknown>;\n  } catch {\n    return {\n      hide: false,\n      confidence: 0,\n      category: \"unknown\",\n      reason: \"Classifier returned invalid JSON\",\n    };\n  }\n\n  const confidence = sanitizeConfidence(parsed.confidence, 0.5);\n  const hide = Boolean(parsed.hide) && confidence >= hideThreshold;\n\n  return {\n    hide,\n    confidence,\n    category: String(parsed.category || \"unknown\").toLowerCase(),\n    reason: cleanReason(parsed.reason || \"LLM classifier decision\"),\n  };\n}\n\ninterface SettingsBundle {\n  filterSelfPromotion: boolean;\n  llmEnabled: boolean;\n  openaiModel: string;\n  llmHideConfidence: number;\n  maxLlmCallsPerMonth: number;\n  openaiApiKey: string;\n  llmUsage: UsageStats | null;\n  llmCache: Record<string, LlmDecision>;\n}\n\nasync function getSettings(): Promise<SettingsBundle> {\n  const [syncRaw, localRaw] = await Promise.all([\n    chrome.storage.sync.get(SYNC_DEFAULT_RECORD),\n    chrome.storage.local.get(LOCAL_DEFAULT_RECORD),\n  ]);\n  const sync = syncRaw as Partial<SyncSettings>;\n  const local = localRaw as Partial<LocalSettings>;\n  const llmCache =\n    local.llmCache && typeof local.llmCache === \"object\"\n      ? (local.llmCache as Record<string, LlmDecision>)\n      : {};\n\n  return {\n    filterSelfPromotion: Boolean(sync.filterSelfPromotion),\n    llmEnabled: Boolean(sync.llmEnabled),\n    openaiModel: String(sync.openaiModel || SYNC_DEFAULTS.openaiModel),\n    llmHideConfidence: sanitizeConfidence(\n      sync.llmHideConfidence,\n      SYNC_DEFAULTS.llmHideConfidence,\n    ),\n    maxLlmCallsPerMonth: Math.max(\n      1,\n      Number(sync.maxLlmCallsPerMonth || SYNC_DEFAULTS.maxLlmCallsPerMonth),\n    ),\n    openaiApiKey: String(local.openaiApiKey || \"\"),\n    llmUsage: local.llmUsage as UsageStats | null,\n    llmCache,\n  };\n}\n\nfunction normalizeUsage(existing: UsageStats | null): UsageStats {\n  const key = monthKey();\n  if (!existing || existing.month !== key) {\n    return { month: key, calls: 0, promptTokens: 0, completionTokens: 0 };\n  }\n  return {\n    month: key,\n    calls: Number(existing.calls || 0),\n    promptTokens: Number(existing.promptTokens || 0),\n    completionTokens: Number(existing.completionTokens || 0),\n  };\n}\n\nfunction cleanupCache(\n  cache: Record<string, LlmDecision>,\n): Record<string, LlmDecision> {\n  const now = Date.now();\n  const entries = Object.entries(cache || {}).filter(([, value]) => {\n    const updatedAt = Number(value?.updatedAt || 0);\n    return updatedAt > 0 && now - updatedAt <= CACHE_TTL_MS;\n  });\n\n  entries.sort((a, b) => Number(b[1].updatedAt) - Number(a[1].updatedAt));\n  return Object.fromEntries(entries.slice(0, MAX_CACHE_ENTRIES));\n}\n\ninterface OpenAiResult {\n  result: ParsedClassifierResult;\n  usage: {\n    promptTokens: number;\n    completionTokens: number;\n  };\n}\n\nasync function runOpenAIClassification(params: {\n  apiKey: string;\n  model: string;\n  hideThreshold: number;\n  localScore: number;\n  filterSelfPromotion: boolean;\n  text: string;\n}): Promise<OpenAiResult> {\n  const truncatedText = String(params.text || \"\").slice(0, 7000);\n  const strictSelfPromoInstruction = params.filterSelfPromotion\n    ? \"Strict self-promo mode is ON: aggressively classify and hide posts with any self-promotional signals, including direct/indirect product links, product-name mentions, launch/early-access copy, 'I built X/I made X' framing, feature lists, call-to-action prompts, or attempts to disguise promotion as discussion.\"\n    : \"Strict self-promo mode is OFF: do not hide purely for self-promotion unless structure strongly looks AI-templated.\";\n\n  const body = {\n    model: params.model,\n    temperature: 0,\n    max_tokens: 120,\n    response_format: { type: \"json_object\" },\n    messages: [\n      {\n        role: \"system\",\n        content:\n          `You classify Reddit posts for feed filtering. Primary criteria are writing cadence, punctuation patterns, and formatting structure (not topic). Focus on AI-templated structure: repetitive short rhetorical lines, polished slogan-like lines, over-structured bullets/framework blocks, and launch narratives with feature-list + CTA. ${strictSelfPromoInstruction} Do NOT treat 'personal experiences' or project-specific details as evidence that content is benign. Strong human-imperfection signals (abbreviations like 'btw'/'ud', malformed punctuation like '.?'/'?!'/'!!', missing capitalization, awkward grammar, spelling slips, and long single-block text with minimal paragraph breaks) are evidence against AI-generation and should bias toward benign unless AI-template structure is strong. Output strict JSON only with keys: hide (boolean), confidence (0..1), category (ai|self_promo|mixed|benign), reason (short). Set hide=true only when evidence is reasonably strong.`,\n      },\n      {\n        role: \"user\",\n        content:\n          `Classify this Reddit post text for feed filtering. Prioritize cadence, punctuation, and formatting structure over topic keywords. Ignore personal-story framing as a benign signal. Local heuristic score: ${params.localScore}.\\n\\n` +\n          truncatedText,\n      },\n    ],\n  };\n\n  const response = await fetch(\"https://api.openai.com/v1/chat/completions\", {\n    method: \"POST\",\n    headers: {\n      Authorization: `Bearer ${params.apiKey}`,\n      \"Content-Type\": \"application/json\",\n    },\n    body: JSON.stringify(body),\n  });\n\n  if (!response.ok) {\n    const textBody = await response.text();\n    throw new Error(\n      `OpenAI request failed (${response.status}): ${textBody.slice(0, 200)}`,\n    );\n  }\n\n  const json = (await response.json()) as {\n    choices?: Array<{ message?: { content?: string } }>;\n    usage?: { prompt_tokens?: number; completion_tokens?: number };\n  };\n\n  const content = json?.choices?.[0]?.message?.content || \"{}\";\n  const result = parseClassifierResult(content, params.hideThreshold);\n\n  return {\n    result,\n    usage: {\n      promptTokens: Number(json?.usage?.prompt_tokens || 0),\n      completionTokens: Number(json?.usage?.completion_tokens || 0),\n    },\n  };\n}\n\nasync function classifyPost(\n  message: ClassifyPostMessage,\n): Promise<ClassifyResponse> {\n  const settings = await getSettings();\n  const usage = normalizeUsage(settings.llmUsage);\n  const cleanedCache = cleanupCache(settings.llmCache);\n\n  if (!settings.llmEnabled) {\n    return { ok: false, skipped: true, reason: \"LLM disabled\" };\n  }\n\n  if (!settings.openaiApiKey) {\n    return { ok: false, skipped: true, reason: \"Missing OpenAI API key\" };\n  }\n\n  if (usage.calls >= settings.maxLlmCallsPerMonth) {\n    return { ok: false, skipped: true, reason: \"Monthly LLM cap reached\" };\n  }\n\n  const rawHash = String(message.postHash || \"\");\n  if (!rawHash) {\n    return { ok: false, skipped: true, reason: \"Missing post hash\" };\n  }\n  const key = `${CLASSIFIER_PROMPT_VERSION}:${settings.filterSelfPromotion ? \"promo-on\" : \"promo-off\"}:${rawHash}`;\n\n  if (cleanedCache[key]) {\n    return { ok: true, cached: true, decision: cleanedCache[key], usage };\n  }\n\n  const { result, usage: tokenUsage } = await runOpenAIClassification({\n    apiKey: settings.openaiApiKey,\n    model: settings.openaiModel,\n    hideThreshold: settings.llmHideConfidence,\n    localScore: Number(message.score || 0),\n    filterSelfPromotion: settings.filterSelfPromotion,\n    text: message.text,\n  });\n\n  const decision: LlmDecision = {\n    hide: Boolean(result.hide),\n    confidence: sanitizeConfidence(result.confidence),\n    category: result.category,\n    reason: result.reason,\n    source: \"openai\",\n    updatedAt: Date.now(),\n  };\n\n  const nextUsage: UsageStats = {\n    month: usage.month,\n    calls: usage.calls + 1,\n    promptTokens: usage.promptTokens + tokenUsage.promptTokens,\n    completionTokens: usage.completionTokens + tokenUsage.completionTokens,\n  };\n\n  cleanedCache[key] = decision;\n  const finalCache = cleanupCache(cleanedCache);\n\n  await chrome.storage.local.set({\n    llmUsage: nextUsage,\n    llmCache: finalCache,\n  });\n\n  return { ok: true, cached: false, decision, usage: nextUsage };\n}\n\nasync function handleGetUsage(): Promise<UsageResponse> {\n  const settings = await getSettings();\n  return {\n    ok: true,\n    usage: normalizeUsage(settings.llmUsage),\n    cacheSize: Object.keys(cleanupCache(settings.llmCache)).length,\n  };\n}\n\nasync function handleClearCache(): Promise<ClearCacheResponse> {\n  await chrome.storage.local.set({ llmCache: {} });\n  return { ok: true };\n}\n\nfunction normalizeBlockedCount(value: unknown): number {\n  const n = Number(value);\n  if (!Number.isFinite(n) || n < 0) return 0;\n  return Math.floor(n);\n}\n\nfunction updateBadge(blockedCount: number): void {\n  const text = blockedCount > 0 ? String(blockedCount) : \"\";\n  chrome.action.setBadgeBackgroundColor({ color: \"#e4572e\" });\n  chrome.action.setBadgeText({ text });\n}\n\nasync function handleIncrementBlocked(): Promise<IncrementBlockedResponse> {\n  const localRaw = await chrome.storage.local.get(LOCAL_DEFAULT_RECORD);\n  const local = localRaw as Partial<LocalSettings>;\n  const next = normalizeBlockedCount(local.blockedCount) + 1;\n  await chrome.storage.local.set({ blockedCount: next });\n  updateBadge(next);\n  return { ok: true, blockedCount: next };\n}\n\nasync function handleGetPopupState(): Promise<PopupStateResponse> {\n  const localRaw = await chrome.storage.local.get(LOCAL_DEFAULT_RECORD);\n  const local = localRaw as Partial<LocalSettings>;\n  const blockedCount = normalizeBlockedCount(local.blockedCount);\n  const hasApiKey = Boolean(String(local.openaiApiKey || \"\").trim());\n  updateBadge(blockedCount);\n  return { ok: true, blockedCount, hasApiKey };\n}\n\nasync function handleSetOpenAiApiKey(\n  apiKey: string,\n): Promise<SetOpenAiApiKeyResponse> {\n  const trimmed = String(apiKey || \"\").trim();\n  await chrome.storage.local.set({ openaiApiKey: trimmed });\n  return { ok: true, hasApiKey: Boolean(trimmed) };\n}\n\nvoid handleGetPopupState();\n\nchrome.runtime.onMessage.addListener(\n  (message: RuntimeMessage, _sender, sendResponse) => {\n    if (!message || typeof message !== \"object\") return;\n\n    if (message.type === \"CLASSIFY_POST\") {\n      classifyPost(message)\n        .then((result) => sendResponse(result))\n        .catch((error: unknown) => {\n          sendResponse({\n            ok: false,\n            skipped: true,\n            reason: String((error as Error)?.message || error),\n          } satisfies ClassifyResponse);\n        });\n      return true;\n    }\n\n    if (message.type === \"GET_USAGE\") {\n      handleGetUsage()\n        .then((result) => sendResponse(result))\n        .catch((error: unknown) => {\n          sendResponse({\n            ok: false,\n            reason: String((error as Error)?.message || error),\n          } satisfies UsageResponse);\n        });\n      return true;\n    }\n\n    if (message.type === \"CLEAR_CACHE\") {\n      handleClearCache()\n        .then((result) => sendResponse(result))\n        .catch((error: unknown) => {\n          sendResponse({\n            ok: false,\n            reason: String((error as Error)?.message || error),\n          } satisfies ClearCacheResponse);\n        });\n      return true;\n    }\n\n    if (message.type === \"INCREMENT_BLOCKED\") {\n      handleIncrementBlocked()\n        .then((result) => sendResponse(result))\n        .catch((error: unknown) => {\n          sendResponse({\n            ok: false,\n            reason: String((error as Error)?.message || error),\n          } satisfies IncrementBlockedResponse);\n        });\n      return true;\n    }\n\n    if (message.type === \"GET_POPUP_STATE\") {\n      handleGetPopupState()\n        .then((result) => sendResponse(result))\n        .catch((error: unknown) => {\n          sendResponse({\n            ok: false,\n            reason: String((error as Error)?.message || error),\n          } satisfies PopupStateResponse);\n        });\n      return true;\n    }\n\n    if (message.type === \"SET_OPENAI_API_KEY\") {\n      handleSetOpenAiApiKey(message.apiKey)\n        .then((result) => sendResponse(result))\n        .catch((error: unknown) => {\n          sendResponse({\n            ok: false,\n            reason: String((error as Error)?.message || error),\n          } satisfies SetOpenAiApiKeyResponse);\n        });\n      return true;\n    }\n  },\n);\n"],
  "mappings": ";AAeA,IAAM,gBAA8B;AAAA,EAClC,SAAS;AAAA,EACT,WAAW;AAAA,EACX,gBAAgB,CAAC;AAAA,EACjB,qBAAqB;AAAA,EACrB,YAAY;AAAA,EACZ,aAAa;AAAA,EACb,mBAAmB;AAAA,EACnB,qBAAqB;AACvB;AACA,IAAM,sBAA+C,EAAE,GAAG,cAAc;AAExE,IAAM,iBAAgC;AAAA,EACpC,cAAc;AAAA,EACd,UAAU;AAAA,EACV,UAAU,CAAC;AAAA,EACX,cAAc;AAChB;AACA,IAAM,uBAAgD,EAAE,GAAG,eAAe;AAE1E,IAAM,eAAe,KAAK,KAAK,KAAK,KAAK;AACzC,IAAM,oBAAoB;AAC1B,IAAM,4BAA4B;AAElC,SAAS,WAAmB;AAC1B,QAAM,MAAM,oBAAI,KAAK;AACrB,QAAM,QAAQ,OAAO,IAAI,SAAS,IAAI,CAAC,EAAE,SAAS,GAAG,GAAG;AACxD,SAAO,GAAG,IAAI,YAAY,CAAC,IAAI,KAAK;AACtC;AAEA,SAAS,YAAY,MAAuB;AAC1C,SAAO,OAAO,QAAQ,EAAE,EACrB,QAAQ,QAAQ,GAAG,EACnB,KAAK,EACL,MAAM,GAAG,GAAG;AACjB;AAEA,SAAS,mBAAmB,OAAgB,WAAW,KAAa;AAClE,QAAM,IAAI,OAAO,KAAK;AACtB,MAAI,CAAC,OAAO,SAAS,CAAC,EAAG,QAAO;AAChC,SAAO,KAAK,IAAI,GAAG,KAAK,IAAI,GAAG,CAAC,CAAC;AACnC;AASA,SAAS,sBACP,SACA,eACwB;AACxB,MAAI;AACJ,MAAI;AACF,aAAS,KAAK,MAAM,OAAO;AAAA,EAC7B,QAAQ;AACN,WAAO;AAAA,MACL,MAAM;AAAA,MACN,YAAY;AAAA,MACZ,UAAU;AAAA,MACV,QAAQ;AAAA,IACV;AAAA,EACF;AAEA,QAAM,aAAa,mBAAmB,OAAO,YAAY,GAAG;AAC5D,QAAM,OAAO,QAAQ,OAAO,IAAI,KAAK,cAAc;AAEnD,SAAO;AAAA,IACL;AAAA,IACA;AAAA,IACA,UAAU,OAAO,OAAO,YAAY,SAAS,EAAE,YAAY;AAAA,IAC3D,QAAQ,YAAY,OAAO,UAAU,yBAAyB;AAAA,EAChE;AACF;AAaA,eAAe,cAAuC;AACpD,QAAM,CAAC,SAAS,QAAQ,IAAI,MAAM,QAAQ,IAAI;AAAA,IAC5C,OAAO,QAAQ,KAAK,IAAI,mBAAmB;AAAA,IAC3C,OAAO,QAAQ,MAAM,IAAI,oBAAoB;AAAA,EAC/C,CAAC;AACD,QAAM,OAAO;AACb,QAAM,QAAQ;AACd,QAAM,WACJ,MAAM,YAAY,OAAO,MAAM,aAAa,WACvC,MAAM,WACP,CAAC;AAEP,SAAO;AAAA,IACL,qBAAqB,QAAQ,KAAK,mBAAmB;AAAA,IACrD,YAAY,QAAQ,KAAK,UAAU;AAAA,IACnC,aAAa,OAAO,KAAK,eAAe,cAAc,WAAW;AAAA,IACjE,mBAAmB;AAAA,MACjB,KAAK;AAAA,MACL,cAAc;AAAA,IAChB;AAAA,IACA,qBAAqB,KAAK;AAAA,MACxB;AAAA,MACA,OAAO,KAAK,uBAAuB,cAAc,mBAAmB;AAAA,IACtE;AAAA,IACA,cAAc,OAAO,MAAM,gBAAgB,EAAE;AAAA,IAC7C,UAAU,MAAM;AAAA,IAChB;AAAA,EACF;AACF;AAEA,SAAS,eAAe,UAAyC;AAC/D,QAAM,MAAM,SAAS;AACrB,MAAI,CAAC,YAAY,SAAS,UAAU,KAAK;AACvC,WAAO,EAAE,OAAO,KAAK,OAAO,GAAG,cAAc,GAAG,kBAAkB,EAAE;AAAA,EACtE;AACA,SAAO;AAAA,IACL,OAAO;AAAA,IACP,OAAO,OAAO,SAAS,SAAS,CAAC;AAAA,IACjC,cAAc,OAAO,SAAS,gBAAgB,CAAC;AAAA,IAC/C,kBAAkB,OAAO,SAAS,oBAAoB,CAAC;AAAA,EACzD;AACF;AAEA,SAAS,aACP,OAC6B;AAC7B,QAAM,MAAM,KAAK,IAAI;AACrB,QAAM,UAAU,OAAO,QAAQ,SAAS,CAAC,CAAC,EAAE,OAAO,CAAC,CAAC,EAAE,KAAK,MAAM;AAChE,UAAM,YAAY,OAAO,OAAO,aAAa,CAAC;AAC9C,WAAO,YAAY,KAAK,MAAM,aAAa;AAAA,EAC7C,CAAC;AAED,UAAQ,KAAK,CAAC,GAAG,MAAM,OAAO,EAAE,CAAC,EAAE,SAAS,IAAI,OAAO,EAAE,CAAC,EAAE,SAAS,CAAC;AACtE,SAAO,OAAO,YAAY,QAAQ,MAAM,GAAG,iBAAiB,CAAC;AAC/D;AAUA,eAAe,wBAAwB,QAOb;AACxB,QAAM,gBAAgB,OAAO,OAAO,QAAQ,EAAE,EAAE,MAAM,GAAG,GAAI;AAC7D,QAAM,6BAA6B,OAAO,sBACtC,0TACA;AAEJ,QAAM,OAAO;AAAA,IACX,OAAO,OAAO;AAAA,IACd,aAAa;AAAA,IACb,YAAY;AAAA,IACZ,iBAAiB,EAAE,MAAM,cAAc;AAAA,IACvC,UAAU;AAAA,MACR;AAAA,QACE,MAAM;AAAA,QACN,SACE,4UAA4U,0BAA0B;AAAA,MAC1W;AAAA,MACA;AAAA,QACE,MAAM;AAAA,QACN,SACE,8MAA8M,OAAO,UAAU;AAAA;AAAA,IAC/N;AAAA,MACJ;AAAA,IACF;AAAA,EACF;AAEA,QAAM,WAAW,MAAM,MAAM,8CAA8C;AAAA,IACzE,QAAQ;AAAA,IACR,SAAS;AAAA,MACP,eAAe,UAAU,OAAO,MAAM;AAAA,MACtC,gBAAgB;AAAA,IAClB;AAAA,IACA,MAAM,KAAK,UAAU,IAAI;AAAA,EAC3B,CAAC;AAED,MAAI,CAAC,SAAS,IAAI;AAChB,UAAM,WAAW,MAAM,SAAS,KAAK;AACrC,UAAM,IAAI;AAAA,MACR,0BAA0B,SAAS,MAAM,MAAM,SAAS,MAAM,GAAG,GAAG,CAAC;AAAA,IACvE;AAAA,EACF;AAEA,QAAM,OAAQ,MAAM,SAAS,KAAK;AAKlC,QAAM,UAAU,MAAM,UAAU,CAAC,GAAG,SAAS,WAAW;AACxD,QAAM,SAAS,sBAAsB,SAAS,OAAO,aAAa;AAElE,SAAO;AAAA,IACL;AAAA,IACA,OAAO;AAAA,MACL,cAAc,OAAO,MAAM,OAAO,iBAAiB,CAAC;AAAA,MACpD,kBAAkB,OAAO,MAAM,OAAO,qBAAqB,CAAC;AAAA,IAC9D;AAAA,EACF;AACF;AAEA,eAAe,aACb,SAC2B;AAC3B,QAAM,WAAW,MAAM,YAAY;AACnC,QAAM,QAAQ,eAAe,SAAS,QAAQ;AAC9C,QAAM,eAAe,aAAa,SAAS,QAAQ;AAEnD,MAAI,CAAC,SAAS,YAAY;AACxB,WAAO,EAAE,IAAI,OAAO,SAAS,MAAM,QAAQ,eAAe;AAAA,EAC5D;AAEA,MAAI,CAAC,SAAS,cAAc;AAC1B,WAAO,EAAE,IAAI,OAAO,SAAS,MAAM,QAAQ,yBAAyB;AAAA,EACtE;AAEA,MAAI,MAAM,SAAS,SAAS,qBAAqB;AAC/C,WAAO,EAAE,IAAI,OAAO,SAAS,MAAM,QAAQ,0BAA0B;AAAA,EACvE;AAEA,QAAM,UAAU,OAAO,QAAQ,YAAY,EAAE;AAC7C,MAAI,CAAC,SAAS;AACZ,WAAO,EAAE,IAAI,OAAO,SAAS,MAAM,QAAQ,oBAAoB;AAAA,EACjE;AACA,QAAM,MAAM,GAAG,yBAAyB,IAAI,SAAS,sBAAsB,aAAa,WAAW,IAAI,OAAO;AAE9G,MAAI,aAAa,GAAG,GAAG;AACrB,WAAO,EAAE,IAAI,MAAM,QAAQ,MAAM,UAAU,aAAa,GAAG,GAAG,MAAM;AAAA,EACtE;AAEA,QAAM,EAAE,QAAQ,OAAO,WAAW,IAAI,MAAM,wBAAwB;AAAA,IAClE,QAAQ,SAAS;AAAA,IACjB,OAAO,SAAS;AAAA,IAChB,eAAe,SAAS;AAAA,IACxB,YAAY,OAAO,QAAQ,SAAS,CAAC;AAAA,IACrC,qBAAqB,SAAS;AAAA,IAC9B,MAAM,QAAQ;AAAA,EAChB,CAAC;AAED,QAAM,WAAwB;AAAA,IAC5B,MAAM,QAAQ,OAAO,IAAI;AAAA,IACzB,YAAY,mBAAmB,OAAO,UAAU;AAAA,IAChD,UAAU,OAAO;AAAA,IACjB,QAAQ,OAAO;AAAA,IACf,QAAQ;AAAA,IACR,WAAW,KAAK,IAAI;AAAA,EACtB;AAEA,QAAM,YAAwB;AAAA,IAC5B,OAAO,MAAM;AAAA,IACb,OAAO,MAAM,QAAQ;AAAA,IACrB,cAAc,MAAM,eAAe,WAAW;AAAA,IAC9C,kBAAkB,MAAM,mBAAmB,WAAW;AAAA,EACxD;AAEA,eAAa,GAAG,IAAI;AACpB,QAAM,aAAa,aAAa,YAAY;AAE5C,QAAM,OAAO,QAAQ,MAAM,IAAI;AAAA,IAC7B,UAAU;AAAA,IACV,UAAU;AAAA,EACZ,CAAC;AAED,SAAO,EAAE,IAAI,MAAM,QAAQ,OAAO,UAAU,OAAO,UAAU;AAC/D;AAEA,eAAe,iBAAyC;AACtD,QAAM,WAAW,MAAM,YAAY;AACnC,SAAO;AAAA,IACL,IAAI;AAAA,IACJ,OAAO,eAAe,SAAS,QAAQ;AAAA,IACvC,WAAW,OAAO,KAAK,aAAa,SAAS,QAAQ,CAAC,EAAE;AAAA,EAC1D;AACF;AAEA,eAAe,mBAAgD;AAC7D,QAAM,OAAO,QAAQ,MAAM,IAAI,EAAE,UAAU,CAAC,EAAE,CAAC;AAC/C,SAAO,EAAE,IAAI,KAAK;AACpB;AAEA,SAAS,sBAAsB,OAAwB;AACrD,QAAM,IAAI,OAAO,KAAK;AACtB,MAAI,CAAC,OAAO,SAAS,CAAC,KAAK,IAAI,EAAG,QAAO;AACzC,SAAO,KAAK,MAAM,CAAC;AACrB;AAEA,SAAS,YAAY,cAA4B;AAC/C,QAAM,OAAO,eAAe,IAAI,OAAO,YAAY,IAAI;AACvD,SAAO,OAAO,wBAAwB,EAAE,OAAO,UAAU,CAAC;AAC1D,SAAO,OAAO,aAAa,EAAE,KAAK,CAAC;AACrC;AAEA,eAAe,yBAA4D;AACzE,QAAM,WAAW,MAAM,OAAO,QAAQ,MAAM,IAAI,oBAAoB;AACpE,QAAM,QAAQ;AACd,QAAM,OAAO,sBAAsB,MAAM,YAAY,IAAI;AACzD,QAAM,OAAO,QAAQ,MAAM,IAAI,EAAE,cAAc,KAAK,CAAC;AACrD,cAAY,IAAI;AAChB,SAAO,EAAE,IAAI,MAAM,cAAc,KAAK;AACxC;AAEA,eAAe,sBAAmD;AAChE,QAAM,WAAW,MAAM,OAAO,QAAQ,MAAM,IAAI,oBAAoB;AACpE,QAAM,QAAQ;AACd,QAAM,eAAe,sBAAsB,MAAM,YAAY;AAC7D,QAAM,YAAY,QAAQ,OAAO,MAAM,gBAAgB,EAAE,EAAE,KAAK,CAAC;AACjE,cAAY,YAAY;AACxB,SAAO,EAAE,IAAI,MAAM,cAAc,UAAU;AAC7C;AAEA,eAAe,sBACb,QACkC;AAClC,QAAM,UAAU,OAAO,UAAU,EAAE,EAAE,KAAK;AAC1C,QAAM,OAAO,QAAQ,MAAM,IAAI,EAAE,cAAc,QAAQ,CAAC;AACxD,SAAO,EAAE,IAAI,MAAM,WAAW,QAAQ,OAAO,EAAE;AACjD;AAEA,KAAK,oBAAoB;AAEzB,OAAO,QAAQ,UAAU;AAAA,EACvB,CAAC,SAAyB,SAAS,iBAAiB;AAClD,QAAI,CAAC,WAAW,OAAO,YAAY,SAAU;AAE7C,QAAI,QAAQ,SAAS,iBAAiB;AACpC,mBAAa,OAAO,EACjB,KAAK,CAAC,WAAW,aAAa,MAAM,CAAC,EACrC,MAAM,CAAC,UAAmB;AACzB,qBAAa;AAAA,UACX,IAAI;AAAA,UACJ,SAAS;AAAA,UACT,QAAQ,OAAQ,OAAiB,WAAW,KAAK;AAAA,QACnD,CAA4B;AAAA,MAC9B,CAAC;AACH,aAAO;AAAA,IACT;AAEA,QAAI,QAAQ,SAAS,aAAa;AAChC,qBAAe,EACZ,KAAK,CAAC,WAAW,aAAa,MAAM,CAAC,EACrC,MAAM,CAAC,UAAmB;AACzB,qBAAa;AAAA,UACX,IAAI;AAAA,UACJ,QAAQ,OAAQ,OAAiB,WAAW,KAAK;AAAA,QACnD,CAAyB;AAAA,MAC3B,CAAC;AACH,aAAO;AAAA,IACT;AAEA,QAAI,QAAQ,SAAS,eAAe;AAClC,uBAAiB,EACd,KAAK,CAAC,WAAW,aAAa,MAAM,CAAC,EACrC,MAAM,CAAC,UAAmB;AACzB,qBAAa;AAAA,UACX,IAAI;AAAA,UACJ,QAAQ,OAAQ,OAAiB,WAAW,KAAK;AAAA,QACnD,CAA8B;AAAA,MAChC,CAAC;AACH,aAAO;AAAA,IACT;AAEA,QAAI,QAAQ,SAAS,qBAAqB;AACxC,6BAAuB,EACpB,KAAK,CAAC,WAAW,aAAa,MAAM,CAAC,EACrC,MAAM,CAAC,UAAmB;AACzB,qBAAa;AAAA,UACX,IAAI;AAAA,UACJ,QAAQ,OAAQ,OAAiB,WAAW,KAAK;AAAA,QACnD,CAAoC;AAAA,MACtC,CAAC;AACH,aAAO;AAAA,IACT;AAEA,QAAI,QAAQ,SAAS,mBAAmB;AACtC,0BAAoB,EACjB,KAAK,CAAC,WAAW,aAAa,MAAM,CAAC,EACrC,MAAM,CAAC,UAAmB;AACzB,qBAAa;AAAA,UACX,IAAI;AAAA,UACJ,QAAQ,OAAQ,OAAiB,WAAW,KAAK;AAAA,QACnD,CAA8B;AAAA,MAChC,CAAC;AACH,aAAO;AAAA,IACT;AAEA,QAAI,QAAQ,SAAS,sBAAsB;AACzC,4BAAsB,QAAQ,MAAM,EACjC,KAAK,CAAC,WAAW,aAAa,MAAM,CAAC,EACrC,MAAM,CAAC,UAAmB;AACzB,qBAAa;AAAA,UACX,IAAI;AAAA,UACJ,QAAQ,OAAQ,OAAiB,WAAW,KAAK;AAAA,QACnD,CAAmC;AAAA,MACrC,CAAC;AACH,aAAO;AAAA,IACT;AAAA,EACF;AACF;",
  "names": []
}
